% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/feature_importance.R
\name{feature.importance}
\alias{feature.importance}
\title{Random forest feature importance}
\usage{
feature.importance(data, x = NULL, y, valid.split = 0.2,
  max.class.levels = 100, cluster.shutdown = TRUE, seed = 1,
  verbose = TRUE)
}
\arguments{
\item{data}{[required | data.frame] Dataset containing predictor and target features}

\item{x}{[optional | character | default=NULL] A vector of feature names present in the dataset used to predict the target feature. If NULL then all columns in the dataset is used.}

\item{y}{[required | character] The name of the target feature contained in the dataset}

\item{valid.split}{[optional | numeric | default=0.2] The percentage of data assigned to the validation partition}

\item{max.class.levels}{[optional | numeric | default=100] The maximum number of unique values in the target feature before it is considered a regression problem.}

\item{cluster.shutdown}{[optional | integer | default=TRUE] Shutdown h2o cluster after completion.}

\item{seed}{[optional | integer | default=1] The random number seed for reproducable results}

\item{verbose}{[optional | logical | default=TRUE] Toggles function to be chatty or not}
}
\value{
List containing a data.frame with feature importance, a feature importance plot and a cumulative feature importance plot
}
\description{
Computes feature importance according to random forest, lasso and light gbm models and then calculates the mean imporatance. The provided data set will be downsampled by random stratified sampling to have a maximum of 60k observations if the dataset has more observations than 60k, training and validation sets are then created. Categortical features are converted to numeric by representing each category as a numeric number for simplicity purposes.A
}
\examples{
imp <- feature.importance(data = iris, x = names(iris)[1:4], y = "Species")
}
\author{
Xander Horn
}
